{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN1cAxdvd61e"
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "  <a href=\"https://sfdt_ibrahim.com/yolo\" target=\"_blank\">\n",
    "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/sfdt_ibrahim/assets/main/yolov8/banner-yolov8.png\"></a>\n",
    "\n",
    "  [‰∏≠Êñá](https://docs.sfdt_ibrahim.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.sfdt_ibrahim.com/ko/) | [Êó•Êú¨Ë™û](https://docs.sfdt_ibrahim.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.sfdt_ibrahim.com/ru/) | [Deutsch](https://docs.sfdt_ibrahim.com/de/) | [Fran√ßais](https://docs.sfdt_ibrahim.com/fr/) | [Espa√±ol](https://docs.sfdt_ibrahim.com/es/) | [Portugu√™s](https://docs.sfdt_ibrahim.com/pt/) | [T√ºrk√ße](https://docs.sfdt_ibrahim.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.sfdt_ibrahim.com/vi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.sfdt_ibrahim.com/ar/)\n",
    "\n",
    "  <a href=\"https://github.com/sfdt_ibrahim/sfdt_ibrahim/actions/workflows/ci.yml\"><img src=\"https://github.com/sfdt_ibrahim/sfdt_ibrahim/actions/workflows/ci.yml/badge.svg\" alt=\"SFDT_Ibrahim CI\"></a>\n",
    "  <a href=\"https://console.paperspace.com/github/sfdt_ibrahim/sfdt_ibrahim\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"/></a>\n",
    "  <a href=\"https://colab.research.google.com/github/sfdt_ibrahim/sfdt_ibrahim/blob/main/examples/object_tracking.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
    "  <a href=\"https://www.kaggle.com/models/sfdt_ibrahim/yolo11\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
    "  <a href=\"https://sfdt_ibrahim.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
    "\n",
    "Welcome to the SFDT_Ibrahim YOLO11 üöÄ notebook! <a href=\"https://github.com/sfdt_ibrahim/sfdt_ibrahim\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://sfdt_ibrahim.com\">SFDT_Ibrahim</a>. This notebook serves as the starting point for exploring the various resources available to help you get started with YOLO11 and understand its features and capabilities.\n",
    "\n",
    "YOLO11 models are fast, accurate, and easy to use, making them ideal for various object detection and image segmentation tasks. They can be trained on large datasets and run on diverse hardware platforms, from CPUs to GPUs.\n",
    "\n",
    "We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.sfdt_ibrahim.com/modes/track/\"> Tracking Docs</a> for details, raise an issue on <a href=\"https://github.com/sfdt_ibrahim/sfdt_ibrahim\">GitHub</a> for support, and join our <a href=\"https://sfdt_ibrahim.com/discord\">Discord</a> community for questions and discussions!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o68Sg1oOeZm2"
   },
   "source": [
    "# Setup\n",
    "\n",
    "Pip install `sfdt_ibrahim` and [dependencies](https://github.com/sfdt_ibrahim/sfdt_ibrahim/blob/main/pyproject.toml) and check software and hardware.\n",
    "\n",
    "[![PyPI - Version](https://img.shields.io/pypi/v/sfdt_ibrahim?logo=pypi&logoColor=white)](https://pypi.org/project/sfdt_ibrahim/) [![Downloads](https://static.pepy.tech/badge/sfdt_ibrahim)](https://www.pepy.tech/projects/sfdt_ibrahim) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/sfdt_ibrahim?logo=python&logoColor=gold)](https://pypi.org/project/sfdt_ibrahim/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dSwz_uOReMI",
    "outputId": "ed8c2370-8fc7-4e4e-f669-d0bae4d944e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFDT_Ibrahim 8.2.17 üöÄ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (T4, 15102MiB)\n",
      "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 29.8/78.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "%pip install sfdt_ibrahim\n",
    "import sfdt_ibrahim\n",
    "\n",
    "sfdt_ibrahim.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7VkxQ2aeg7k"
   },
   "source": [
    "# SFDT_Ibrahim Object Tracking\n",
    "\n",
    "[SFDT_Ibrahim YOLO11](https://github.com/sfdt_ibrahim/sfdt_ibrahim/) instance segmentation involves identifying and outlining individual objects in an image, providing a detailed understanding of spatial distribution. Unlike semantic segmentation, it uniquely labels and precisely delineates each object, crucial for tasks like object detection and medical imaging.\n",
    "\n",
    "There are two types of instance segmentation tracking available in the SFDT_Ibrahim package:\n",
    "\n",
    "- **Instance Segmentation with Class Objects:** Each class object is assigned a unique color for clear visual separation.\n",
    "\n",
    "- **Instance Segmentation with Object Tracks:** Every track is represented by a distinct color, facilitating easy identification and tracking.\n",
    "\n",
    "## Samples\n",
    "\n",
    "|                                                          Instance Segmentation                                                          |                                                           Instance Segmentation + Object Tracking                                                            |\n",
    "|:---------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| ![SFDT_Ibrahim Instance Segmentation](https://github.com/RizwanMunawar/sfdt_ibrahim/assets/62513924/d4ad3499-1f33-4871-8fbc-1be0b2643aa2) | ![SFDT_Ibrahim Instance Segmentation with Object Tracking](https://github.com/RizwanMunawar/sfdt_ibrahim/assets/62513924/2e5c38cc-fd5c-4145-9682-fa94ae2010a0) |\n",
    "|                                                  SFDT_Ibrahim Instance Segmentation üòç                                                   |                                                  SFDT_Ibrahim Instance Segmentation with Object Tracking üî•                                                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZF9DM6e6gz0"
   },
   "source": [
    "## CLI\n",
    "\n",
    "Command-Line Interface (CLI) example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XJqhOwo6iqT"
   },
   "outputs": [],
   "source": [
    "!yolo track source=\"/path/to/video/file.mp4\" save=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRcw0vIE6oNb"
   },
   "source": [
    "## Python\n",
    "\n",
    "Python Instance Segmentation and Object tracking example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cx-u59HQdu2o"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sfdt_ibrahim import YOLO\n",
    "from sfdt_ibrahim.utils.plotting import Annotator, colors\n",
    "\n",
    "# Dictionary to store tracking history with default empty lists\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "# Load the YOLO model with segmentation capabilities\n",
    "model = YOLO(\"yolo11n-seg.pt\")\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(\"path/to/video/file.mp4\")\n",
    "\n",
    "# Retrieve video properties: width, height, and frames per second\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Initialize video writer to save the output video with the specified properties\n",
    "out = cv2.VideoWriter(\"instance-segmentation-object-tracking.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), fps, (w, h))\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, im0 = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    # Create an annotator object to draw on the frame\n",
    "    annotator = Annotator(im0, line_width=2)\n",
    "\n",
    "    # Perform object tracking on the current frame\n",
    "    results = model.track(im0, persist=True)\n",
    "\n",
    "    # Check if tracking IDs and masks are present in the results\n",
    "    if results[0].boxes.id is not None and results[0].masks is not None:\n",
    "        # Extract masks and tracking IDs\n",
    "        masks = results[0].masks.xy\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "        # Annotate each mask with its corresponding tracking ID and color\n",
    "        for mask, track_id in zip(masks, track_ids):\n",
    "            annotator.seg_bbox(mask=mask, mask_color=colors(int(track_id), True), label=str(track_id))\n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    out.write(im0)\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow(\"instance-segmentation-object-tracking\", im0)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video writer and capture objects, and close all OpenCV windows\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrlKg-y3fEyD"
   },
   "source": [
    "# Additional Resources\n",
    "\n",
    "## Community Support\n",
    "\n",
    "For more information on using tracking with SFDT_Ibrahim, you can explore the comprehensive [SFDT_Ibrahim Tracking Docs](https://docs.sfdt_ibrahim.com/modes/track/). This guide covers everything from basic concepts to advanced techniques, ensuring you get the most out of tracking and visualization.\n",
    "\n",
    "## SFDT_Ibrahim ‚ö° Resources\n",
    "\n",
    "At SFDT_Ibrahim, we are committed to providing cutting-edge AI solutions. Here are some key resources to learn more about our company and get involved with our community:\n",
    "\n",
    "- [SFDT_Ibrahim HUB](https://sfdt_ibrahim.com/hub): Simplify your AI projects with SFDT_Ibrahim HUB, our no-code tool for effortless YOLO training and deployment.\n",
    "- [SFDT_Ibrahim Licensing](https://sfdt_ibrahim.com/license): Review our licensing terms to understand how you can use our software in your projects.\n",
    "- [About Us](https://sfdt_ibrahim.com/about): Discover our mission, vision, and the story behind SFDT_Ibrahim.\n",
    "- [Join Our Team](https://sfdt_ibrahim.com/work): Explore career opportunities and join our team of talented professionals.\n",
    "\n",
    "## YOLO11 üöÄ Resources\n",
    "\n",
    "YOLO11 is the latest evolution in the YOLO series, offering state-of-the-art performance in object detection and image segmentation. Here are some essential resources to help you get started with YOLO11:\n",
    "\n",
    "- [GitHub](https://github.com/sfdt_ibrahim/sfdt_ibrahim): Access the YOLO11 repository on GitHub, where you can find the source code, contribute to the project, and report issues.\n",
    "- [Docs](https://docs.sfdt_ibrahim.com/): Explore the official documentation for YOLO11, including installation guides, tutorials, and detailed API references.\n",
    "- [Discord](https://sfdt_ibrahim.com/discord): Join our Discord community to connect with other users, share your projects, and get help from the SFDT_Ibrahim team.\n",
    "\n",
    "These resources are designed to help you leverage the full potential of SFDT_Ibrahim' offerings and YOLO11. Whether you're a beginner or an experienced developer, you'll find the information and support you need to succeed."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
